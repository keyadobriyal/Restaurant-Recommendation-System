{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8RQiDDp7YOj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abstract\n",
        "A Restaurant Recommendation System is proposed to address the challenge users face in choosing from the vast and growing number of restaurant options. Leveraging content-based filtering techniques, the system analyzes user preferences, locality, ratings, cuisine, and past experiences to provide personalized suggestions.\n",
        "The primary goal is to save user time and simplify the decision-making process by filtering a large dataset and providing the most relevant restaurant recommendations. Developed using Python libraries and machine learning (including data preprocessing, vectorization, and cosine similarity), the system increases user convenience and business retention rates. Future enhancements include incorporating collaborative filtering and real-time feedback to evolve into a more accurate hybrid recommendation system. This tool offers an efficient solution to the contemporary need for quick and easy decision support in the food industry.\n",
        "#Keywords\n",
        "Recommender System, Preferences, multi-criteria methods, machine learning, Restaurant Recommendation, locations, Rating\n",
        "#Key Objectives of the Restaurant Recommendation System\n",
        "The main goal of creating this restaurant recommendation system is to help users discover restaurants tailored to their individual preferences and past interactions. It is designed to offer a personalized, convenient, and efficient experience.\n",
        "This system achieves its objectives by:\n",
        "- **Saving Time:** It suggests relevant restaurants, eliminating the need for users to manually browse through countless options.\n",
        "- **Simplifying Decisions:** By filtering and narrowing down widespread choices, it allows users to make well-informed decisions. All key information and attributes are easily accessible for comparison.\n",
        "- **Enhancing User Satisfaction:** It targets an interactive experience by recommending options most likely to be enjoyed based on the user's currently selected restaurant or cuisine.\n",
        "Ultimately, a successful recommendation system will significantly contribute to higher customer satisfaction and retention rates, addressing a major challenge for businesses in the food service industry.\n",
        "#How a recommendation system works?\n",
        "The exponential growth of data collection has ushered in a new era driven by data-centric innovation. This vast data is leveraged to design smarter and more efficient systems, among which recommender systems play a key role.\n",
        "Recommender systems function as information-filtering tools that enhance search quality by presenting results most relevant to a user‚Äôs query or aligned with their past interactions and preferences. There are basic five types of recommender system:\n",
        "##Content-Based Filtering System\n",
        "A content-based filtering system recommends items similar to those already selected by a user by comparing their features using methods such as cosine similarity or Euclidean distance. In the restaurant recommendation system, attributes like location, rating, and cost are analyzed to suggest similar restaurants. It offers a personalized experience based solely on individual preferences without relying on data from other users.\n",
        "##Collaborative Filtering System\n",
        "Collaborative filtering predicts user preferences by comparing their activity with others who have similar interests. It can be user‚Äìuser (recommending what similar users liked) or item‚Äìitem (suggesting similar items to those a user enjoyed). Though effective, it requires large datasets and struggles with new users or items due to lack of prior information.\n",
        "##Hybrid Recommendation System\n",
        "A hybrid system integrates multiple techniques, typically combining content-based and collaborative filtering to balance their strengths and weaknesses. Common methods include weighted, switching, and mixed approaches. While more complex and data-heavy, hybrid systems deliver more accurate, diverse, and personalized results.\n",
        "##Knowledge-Based Recommendation System\n",
        "Knowledge-based systems match user requirements with specific item attributes instead of using past behavior. Ideal for users with clear preferences, they rely on structured item data (e.g., cost, rating, or location) and use rule-based or constraint-based reasoning to generate precise suggestions.\n",
        "##Context-Aware Recommendation System\n",
        "Context-aware systems consider external factors such as time, location, weather, or mood when generating recommendations. By integrating contextual data with user and item profiles, they provide adaptive and relevant suggestions. However, these systems can be costly to implement and raise privacy concerns due to the extensive data collection required.\n",
        "#Getting Started with Data and Strategy\n",
        "To build our recommendation system, we first need a robust dataset with key features for analysis. We require details such as restaurant name, rating, cost, and user reviews to identify similarities and make accurate suggestions.\n",
        "##Data\n",
        "Dineout is a table booking platform helping customers to do table booking in their favourite restaurants for free and help them get great discounts. The Dineout dataset have been downloaded from Kaggle (https://www.kaggle.com/datasets/arnabchaki/indian-restaurants-2023)  and includes thousands of restaurants with attributes such as location data, average rating, number of reviews, cuisine types, etc.\n",
        "\n",
        "The dataset combines the restaurants from the main Indian cities and I shall be using this dataset for building restaurant recommendation system.\n",
        "\n",
        "##Strategy\n",
        "My approach will employ Content-Based Filtering to generate personalized restaurant recommendations for each user.\n",
        "I use TF-IDF and Cosine Similarity to calculate similarity between user's description and restaurant reviews and then return a list of restaurants sorted by similarity.\n",
        "##Key Libraries Used in the System\n",
        "Developing a machine learning project starts by importing Python libraries to provide ready-to-use functions for data processing, text vectorization, and similarity computation, reducing development complexity.\n",
        "###Pandas and NumPy\n",
        "**Pandas** is used for data handling and preprocessing, enabling efficient cleaning, organization, and manipulation of datasets in tabular form.\n",
        "**NumPy** supports numerical computations using multi-dimensional arrays and matrices, aiding in feature transformation and similarity calculations.\n",
        "###Streamlit\n",
        "**Streamlit** is an open-source Python library for creating interactive web applications. It enables users to search, select, and input preferences while allowing developers to build dynamic dashboards and interfaces with minimal effort.\n",
        "###Scikit-learn\n",
        "**Scikit-learn** is central to feature extraction and modeling. It converts text data into numerical form through vectorization and computes restaurant similarity using cosine similarity measures.\n",
        "###Pickle\n",
        "**Pickle** is used to serialize and store objects such as models, matrices, and dataframes locally. In this system, it saves the TF-IDF vectorizer, cosine similarity matrix, and preprocessed data, improving efficiency by avoiding repetitive loading.\n",
        "#Methodology\n",
        "##Data Preprocessing\n",
        "Effective data preprocessing ensures accuracy and reliability in recommendation systems. The main steps followed are:\n",
        "###Removal of Null Values\n",
        "Missing values were detected using isnull() and sum() functions and appropriately handled to maintain data integrity. Removing nulls ensures consistent feature combination and reliable similarity computation.\n",
        "###Deleting Duplicate Values\n",
        "Duplicate entries, often caused by data merging or manual errors, were removed using Pandas‚Äô drop_duplicates() to prevent bias in similarity calculations and improve computational efficiency.\n",
        "###Selecting Relevant Columns\n",
        "Only essential features‚ÄîName, Cuisine, Location, City, and Locality‚Äîwere retained to focus on meaningful attributes affecting restaurant similarity and to reduce processing overhead.\n",
        "###Removal of Spaces\n",
        "Irregular spacing in text fields was standardized using string replacement to ensure consistent categorical values (e.g., ‚ÄúNorth Indian‚Äù and ‚ÄúNorthIndian‚Äù treated uniformly).\n",
        "###Text Normalization (Lowercase Conversion)\n",
        "All text entries were converted to lowercase using .str.lower() to eliminate case-based discrepancies, improving vectorization accuracy and reducing vocabulary redundancy.\n",
        "###Merging Columns\n",
        "Key text attributes (Cuisine, Locality, City, Location) were concatenated into a single ‚Äúcombined_features‚Äù column, creating a comprehensive representation of each restaurant. This facilitates more efficient vectorization and enhances similarity detection during recommendations.\n",
        "##Vectorization: Converting Text to Numerical Data üî¢\n",
        "Vectorization is the process of converting raw, unstructured textual data into numeric vectors that machine learning models can process, all while preserving the data's original meaning. This conversion is a prerequisite for building computational models, as it facilitates faster computation and provides the necessary input format for algorithms.\n",
        "In this project, we employ the CountVectorizer function from the scikit-learn library.\n",
        "- **Mechanism:** CountVectorizer converts a collection of text documents (in our case, the \"combined_features\" column) into a structured matrix where each dimension represents a word's frequency within a restaurant's feature set.\n",
        " - **Application:** This technique encodes textual attributes like cuisine, location, ratings, and cost into vectors.\n",
        "- **Result:** The resulting numeric vectors are then used to compute similarities between restaurants, forming the essential foundation for the content-based filtering system to identify and suggest comparable options.\n",
        "##Computing Cosine Similarity üìê\n",
        "After vectorization, cosine similarity is computed to measure the degree of resemblance between every restaurant in the dataset.\n",
        "-\t**Mechanism:** Cosine similarity calculates the angle between two non-zero vectors in a multi-dimensional space. A higher score (closer to 1) indicates a greater degree of closeness between two restaurants' vector representations.\n",
        "-\t**Application:** The vectors are created from the combined textual attributes (cuisine, location, rating, cost).\n",
        "-\t**Result:** This pairwise computation forms a similarity matrix, where each entry is the similarity score between any two restaurants. This matrix is the central component for the recommendation process. When a user selects a restaurant, its vector is compared against all others in the matrix to find the most highly matched options, enabling personalized dining recommendations.\n",
        "##Frontend Development (Streamlit) üíª\n",
        "The frontend of the Restaurant Recommendation System is a user-friendly and visually engaging interface built using the Python **Streamlit library**. The frontend serves as the essential platform for user interaction.\n",
        "- **User Experience:** The design prioritizes interactivity, visual appeal, and ease of use to maximize user engagement and minimize the effort required to find a restaurant.\n",
        "- **Implementation:** We used standard Streamlit functions like st.title(), st.header(), and st.markdown(). Custom HTML designs were incorporated using st.markdown() to enhance visual attractiveness.\n",
        "-\t**User Input:** Interactive widgets are used to collect user input, including:\n",
        "1. Drop-down menus (st.selectbox()\n",
        "2. Search bars (st.text_input()\n",
        "3. Action buttons (st.button()\n",
        "- **Output:** The interface is responsible for clearly displaying the processed recommendations using functions like st.write() and st.dataframe().\n",
        "The frontend effectively acts as the bridge between the user and the backend's recommendation logic, making the system accessible and practical.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "00ZbamOw8IUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING LIBRARIES\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "\n",
        "# --- DATA PREPROCESSING ---\n",
        "# Reading dataset (Note: Ensure 'restaurants.csv' is in the same directory)\n",
        "df = pd.read_csv('restaurants.csv')\n",
        "\n",
        "# Show table info\n",
        "print(df.info())\n",
        "\n",
        "# Printing first 5 rows in dataset\n",
        "print(\"\\n--- First 5 rows (Original) ---\")\n",
        "print(df.head())\n",
        "\n",
        "# Checking for null values\n",
        "print(\"\\n--- Null Value Count ---\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Deleting any duplicate values\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Updating relevant columns\n",
        "df = df[['Name', 'Cuisine', 'Location', 'City', 'Locality']].copy()\n",
        "\n",
        "# Deleting spaces in key columns\n",
        "print(\"\\n--- Removing Spaces ---\")\n",
        "df['Location'] = df['Location'].astype(str).str.replace(' ', '')\n",
        "df['Cuisine'] = df['Cuisine'].astype(str).str.replace(' ', '')\n",
        "df['Locality'] = df['Locality'].astype(str).str.replace(' ', '')\n",
        "\n",
        "# Print first 5 lines after space removal\n",
        "print(df.head())\n",
        "\n",
        "# Converting strings to lowercase and removing leading/trailing spaces\n",
        "print(\"\\n--- Converting to Lowercase ---\")\n",
        "for col in ['Cuisine', 'Location', 'City', 'Locality']:\n",
        "    # Ensure the column is treated as string before applying string methods\n",
        "    df[col] = df[col].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Print first 5 lines after lowercasing\n",
        "print(df.head())\n",
        "\n",
        "# Merge all columns into a single 'combined_features' column\n",
        "def combine_features(row):\n",
        "    return f\"{row['Cuisine']} {row['Location']} {row['City']} {row['Locality']}\"\n",
        "\n",
        "df['combined_features'] = df.apply(combine_features, axis=1)\n",
        "\n",
        "# Print first 5 lines after merging\n",
        "print(\"\\n--- After Merging Features ---\")\n",
        "print(df.head())\n",
        "\n",
        "# --- VECTORIZATION ---\n",
        "# Vectorization of combined features using CountVectorizer\n",
        "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
        "vectors = cv.fit_transform(df['combined_features']).toarray()\n",
        "\n",
        "# --- COSINE SIMILARITY ---\n",
        "# Compute cosine similarity between vectors\n",
        "similarity = cosine_similarity(vectors)\n",
        "\n",
        "# Print similarity values for the first restaurant\n",
        "print(\"\\n--- Similarity values for the first restaurant ---\")\n",
        "# Only print a snippet as the array is large\n",
        "print(similarity[0][:10])\n",
        "\n",
        "# --- RECOMMENDATION FUNCTION ---\n",
        "def recommend(restaurant_name):\n",
        "    # Find the index of the given restaurant name\n",
        "    try:\n",
        "        restaurant_index = df[df['Name'] == restaurant_name].index[0]\n",
        "    except IndexError:\n",
        "        print(f\"Restaurant '{restaurant_name}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Get similarity distances for that restaurant\n",
        "    distance = similarity[restaurant_index]\n",
        "\n",
        "    # Get top 5 most similar restaurants (excluding itself)\n",
        "    # enumerate creates (index, distance) pairs\n",
        "    restaurant_List = sorted(\n",
        "        list(enumerate(distance)),\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )[1:6]\n",
        "\n",
        "    print(f\"\\n--- Top 5 recommendations for '{restaurant_name}' ---\")\n",
        "    # Print the names of those restaurants\n",
        "    for i in restaurant_List:\n",
        "        print(df.iloc[i[0]]['Name'])\n",
        "\n",
        "# Testing the function\n",
        "recommend('Tamasha')\n",
        "# Note: The raw print statement for index 0 was redundant after defining the function.\n",
        "\n",
        "# --- SAVING OBJECTS WITH PICKLE ---\n",
        "print(\"\\n--- Saving objects with pickle ---\")\n",
        "\n",
        "# Save the DataFrame (converted to a dictionary for easier Streamlit use)\n",
        "# Using 'df' directly is fine, but a dict might be marginally better for web apps\n",
        "pickle.dump(df.to_dict(), open('restaurant_dict.pkl', 'wb'))\n",
        "\n",
        "# Save the similarity matrix\n",
        "pickle.dump(similarity, open('similarity.pkl', 'wb'))\n",
        "\n",
        "print(\"Objects saved: 'restaurant_dict.pkl' and 'similarity.pkl'\")\n"
      ],
      "metadata": {
        "id": "qkvyHB8RgkIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "outputId": "cd1a49ca-31a1-457f-a602-cf484f2bf1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'restaurants.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3958259643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# --- DATA PREPROCESSING ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Reading dataset (Note: Ensure 'restaurants.csv' is in the same directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'restaurants.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Show table info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'restaurants.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frontend code for web application of restaurant recommendation system\n",
        "This code has been written using python in PyCharm\n",
        "\n"
      ],
      "metadata": {
        "id": "sXCLSAMIBulN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- IMPORTS -----------------\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------- LOAD DATA -----------------\n",
        "restaurant_dict = pickle.load(open('restaurant_dict.pkl', 'rb'))\n",
        "restaurant_df = pd.DataFrame(restaurant_dict)\n",
        "similarity = pickle.load(open('similarity.pkl', 'rb'))\n",
        "\n",
        "# ----------------- SESSION STATE -----------------\n",
        "if 'page' not in st.session_state:\n",
        "    st.session_state.page = 'welcome'\n",
        "\n",
        "# ----------------- RECOMMENDATION FUNCTION -----------------\n",
        "def recommend(restaurant):\n",
        "    if restaurant not in restaurant_df['Name'].values:\n",
        "        return []\n",
        "\n",
        "    restaurant_index = restaurant_df[restaurant_df['Name'] == restaurant].index[0]\n",
        "    distance = similarity[restaurant_index]\n",
        "    restaurant_list = sorted(\n",
        "        list(enumerate(distance)),\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )[1:6]\n",
        "\n",
        "    return [restaurant_df.iloc[i[0]].Name for i in restaurant_list]\n",
        "\n",
        "# ----------------- WELCOME PAGE -----------------\n",
        "if st.session_state.page == 'welcome':\n",
        "    st.markdown(\"\"\"\n",
        "    <div style=\"text-align: center; padding-top: 80px;\">\n",
        "        <h1 style=\"font-size: 60px; font-weight: bold; color: #FF6347;\">\n",
        "            üçΩÔ∏è <span style=\"color:#FF6347;\">Welcome to</span>\n",
        "            <span style=\"color:#2E8B57;\"> Delicious Bites</span>!\n",
        "        </h1>\n",
        "        <p style=\"font-size: 22px; color: #aaaaaa; margin-top: 10px;\">\n",
        "            Experience the taste that makes you smile üçΩÔ∏è\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"<br><br>\", unsafe_allow_html=True)\n",
        "    col1, col2, col3 = st.columns([3, 1, 3])\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\" Enter App \", use_container_width=True):\n",
        "            st.session_state.page = 'main'\n",
        "            st.rerun()\n",
        "\n",
        "# ----------------- MAIN PAGE -----------------\n",
        "elif st.session_state.page == 'main':\n",
        "    st.title('üçΩÔ∏è Restaurant Recommender System')\n",
        "\n",
        "    selected_restaurant_name = st.selectbox(\n",
        "        'Select a restaurant you like:',\n",
        "        restaurant_df['Name'].values\n",
        "    )\n",
        "\n",
        "    if st.button('Recommend'):\n",
        "        recommendations = recommend(selected_restaurant_name)\n",
        "\n",
        "        if recommendations:\n",
        "            st.subheader(\"You might also like:\")\n",
        "            for i in recommendations:\n",
        "                st.write(f\"üçΩÔ∏è  {i}\")\n",
        "        else:\n",
        "            st.warning(\"No recommendations found for the selected restaurant.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # ----------------- CUISINE DASHBOARD -----------------\n",
        "    st.header(\"üìä Restaurant Dashboard by Cuisine\")\n",
        "\n",
        "    # Load original dataset for cuisine analysis\n",
        "    restaurant_data = pd.read_csv(\"restaurants.csv\")\n",
        "\n",
        "    # Extract unique cuisines\n",
        "    cuisine_list = set()\n",
        "    for c in restaurant_data['Cuisine'].dropna():\n",
        "        for item in c.split(','):\n",
        "            cuisine_list.add(item.strip())\n",
        "\n",
        "    cuisine_list = sorted(cuisine_list)\n",
        "\n",
        "    # Cuisine selector\n",
        "    selected_cuisine = st.selectbox(\"Choose a Cuisine\", cuisine_list)\n",
        "\n",
        "    # Filter function\n",
        "    def filter_by_cuisine(cuisine):\n",
        "        return restaurant_data[\n",
        "            restaurant_data['Cuisine'].str.contains(cuisine, case=False, na=False)\n",
        "        ]\n",
        "\n",
        "    # Apply filter\n",
        "    filtered_df = filter_by_cuisine(selected_cuisine)\n",
        "\n",
        "    # Format cost and rating\n",
        "    if 'Cost' in filtered_df.columns:\n",
        "        filtered_df['Cost'] = filtered_df['Cost'].apply(\n",
        "            lambda x: f\"‚Çπ{x}\" if pd.notnull(x) else 'N/A'\n",
        "        )\n",
        "    if 'Rating' in filtered_df.columns:\n",
        "        filtered_df['Rating'] = filtered_df['Rating'].apply(\n",
        "            lambda x: round(x, 1) if pd.notnull(x) else 'N/A'\n",
        "        )\n",
        "\n",
        "    # Display results\n",
        "    st.write(f\"### Restaurants offering *{selected_cuisine}* cuisine:\")\n",
        "    st.dataframe(\n",
        "        filtered_df[['Name', 'Cuisine', 'Location', 'City', 'Cost', 'Rating']].reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Exit Button\n",
        "    if st.button(\"‚ùå Exit App\"):\n",
        "        st.success(\"Thank you for visiting Delicious Bites! üçΩÔ∏è\")\n",
        "        st.stop()\n"
      ],
      "metadata": {
        "id": "lIZSojlrluH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "This recommendation system successfully developed an accurate, scalable and user-friendly restaurant recommendations using content-based filtering. The system efficiently addresses challenges faced by both users (decision fatigue, time saving) and businesses (customer retention) by analysing user preferences such as cuisine, location, and cost, ensuring a reliable and satisfying experience for every user.\n",
        "##Key Achievements:\n",
        "- **Solves Cold-Start Problem:** Recommendations are provided immediately, even for new consumers with no prior interaction history.\n",
        "- **Single-User Usability:** It functions effectively without requiring data from multiple users, respecting user privacy regarding personal locations and preferences.\n",
        "- **Machine Learning Integration:** The platform integrates data preprocessing, vectorization, and cosine similarity computation, all presented through a user-friendly web interface built with Streamlit.\n",
        "- **Business Impact:** By providing fast and reliable suggestions, it aims to increase customer return rates and boost business growth in the rapidly expanding food industry.\n",
        "The system is a strong foundation that can be scaled and improved in the future by incorporating more advanced techniques like collaborative filtering and real-time feedback  to enhance personalization and accessibility, making it an ideal example of leveraging technology to solve everyday issues.\n",
        "#About the Authors\n",
        "**Keya Dobriyal** is pursuing a B.E. in Computer Science with Honors in Data Science at Amity University, Noida. Her core expertise and interests include data wrangling and manipulation, data visualization, machine learning, and storytelling with big data technologies, with a focus on using Python and R to transform raw data into actionable insights. She is also passionate about creative writing and art. This article is part of a project completed as a component of her academic coursework.\n",
        "\n",
        "**Shreya Gupta** is pursuing a B.E. degree in Computer Science at Amity University, Noida. Her interest spans data anlaytics, machine learning and data visualization.\n"
      ],
      "metadata": {
        "id": "VkiptpNoEy_y"
      }
    }
  ]
}